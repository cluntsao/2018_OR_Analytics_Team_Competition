{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_df_generator(df, correct_index):\n",
    "    '''Transform cov_mat file into complete diagonal matrix'''\n",
    "    \n",
    "    df_temp = df.pivot_table(index='ROW_INDEX', columns='COLUMN_INDEX', values='VALUE', fill_value = 0)\n",
    "    \n",
    "    df_original = df_temp.copy()\n",
    "    \n",
    "    np.fill_diagonal(df_temp.values, 0)\n",
    "    \n",
    "    final_df = (df_original.T + df_temp).reindex(index = correct_index, columns = correct_index)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def minimum_weight_constraint(df):\n",
    "    in_constraint = True\n",
    "    \n",
    "    for weight in df[\"WEIGHTS\"][df[\"WEIGHTS\"] > 0]:\n",
    "        if weight < 0.001:\n",
    "            in_constraint = False\n",
    "            break\n",
    "    \n",
    "    return in_constraint\n",
    "\n",
    "def num_of_portfolio_constraint(df):\n",
    "    in_constraint = True\n",
    "    \n",
    "    if 50 <= np.count_nonzero(df[\"WEIGHTS\"]) <= 70:\n",
    "        pass\n",
    "    else:\n",
    "        in_constraint = False\n",
    "        \n",
    "    return in_constraint\n",
    "\n",
    "def tracking_error_constraint(df, cov_df):\n",
    "    in_constraint = True\n",
    "    df_matrix = np.matrix(df[\"WEIGHT_DIFF\"])\n",
    "    cov_df_matrix = np.matrix(cov_df)\n",
    "    \n",
    "    traking_error = np.sqrt(df_matrix * cov_df_matrix * df_matrix.T)\n",
    "    \n",
    "    if (traking_error < 0.05) or (traking_error > 0.1):\n",
    "        in_constraint = False\n",
    "    \n",
    "    return in_constraint\n",
    "\n",
    "def weight_diff_constraint(df):\n",
    "    in_constraint = True\n",
    "    \n",
    "    if (max(df[\"WEIGHT_DIFF\"]) >= 0.05) or (min(df[\"WEIGHT_DIFF\"]) <= -0.05):\n",
    "        in_constraint = False\n",
    "        \n",
    "    return in_constraint\n",
    "\n",
    "def mcapq_constraint(df):\n",
    "    in_constraint = True\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        if bool(-0.1 <= sum(df[\"WEIGHT_DIFF\"][df[\"MCAP_Q\"] ==  i ]) <= 0.1):\n",
    "            pass\n",
    "        else:\n",
    "            in_constraint = False\n",
    "            break\n",
    "        \n",
    "    return in_constraint\n",
    "\n",
    "\n",
    "def sector_constraint(df):\n",
    "    in_constraint = True\n",
    "    \n",
    "    for i in df[\"SECTOR\"].unique():\n",
    "        if bool(-0.1 <= sum(df[\"WEIGHT_DIFF\"][df[\"SECTOR\"] == i]) <= 0.1):\n",
    "            pass\n",
    "        else:\n",
    "            in_constraint = False\n",
    "            break\n",
    "    return in_constraint\n",
    "\n",
    "def active_share_constraint(df):\n",
    "    in_constraint = True\n",
    "    \n",
    "    if bool(0.6 <= (1 - sum(np.minimum(df[\"WEIGHTS\"], df[\"BENCH_WEIGHT\"]))) <= 1.0):\n",
    "        pass\n",
    "    else:\n",
    "        in_constraint = False\n",
    "    \n",
    "    return in_constraint\n",
    "\n",
    "def beta_constraint(df):\n",
    "    in_constraint = True\n",
    "    \n",
    "    if abs((df[\"WEIGHT_DIFF\"] * df[\"BETA\"]).sum()) > 0.1:\n",
    "        in_constraint = False\n",
    "    \n",
    "    return in_constraint\n",
    "\n",
    "\n",
    "def meet_constraints(df, cov_df):\n",
    "    '''For all Constraints'''\n",
    "    in_all_constraints = True\n",
    "    \n",
    "    if num_of_portfolio_constraint(df):\n",
    "        if minimum_weight_constraint(df):\n",
    "            if weight_diff_constraint(df):\n",
    "                if beta_constraint(df):\n",
    "                    if sector_constraint(df):\n",
    "                        if mcapq_constraint(df):\n",
    "                            if active_share_constraint(df):\n",
    "                                if tracking_error_constraint(df, cov_df):\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    in_all_constraints = False\n",
    "                            else:\n",
    "                                in_all_constraints = False\n",
    "                        else:\n",
    "                            in_all_constraints = False\n",
    "                    else:\n",
    "                        in_all_constraints = False\n",
    "                else:\n",
    "                    in_all_constraints = False\n",
    "            else:\n",
    "                in_all_constraints = False\n",
    "        else:\n",
    "            in_all_constraints = False\n",
    "    else:\n",
    "        in_all_constraints = False\n",
    "    \n",
    "    return in_all_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions using in Scipy.Minimize\n",
    "def objective(x):\n",
    "\n",
    "    return (np.matrix(x - BENCH) * np.matrix(cov_df_temp) * np.matrix(x - BENCH).T) - \\\n",
    "           (LAMBDA * np.matrix(x - BENCH) * np.matrix(ALPHA).T)\n",
    "\n",
    "def constraint4(x):\n",
    "    SUM = 1\n",
    "    return x.sum() - SUM\n",
    "\n",
    "def constraint5(x):\n",
    "\n",
    "    return (0.05 - abs(x - BENCH))\n",
    "\n",
    "def constraint6(x):\n",
    "\n",
    "    sector_list = []\n",
    "\n",
    "    for sector in df_temp[\"SECTOR\"].unique():\n",
    "        sector_list.append(abs(sum(x[sector_iindex_dict[sector]] - df_temp[\"BENCH_WEIGHT\"][sector_iindex_dict[sector]])))\n",
    "\n",
    "    return 0.1 - np.array(sector_list)\n",
    "\n",
    "def constraint7(x):\n",
    "    mcapq_list = []\n",
    "\n",
    "    for mcapq in range(1, 6):\n",
    "        mcapq_list.append(abs(sum(x[mcapq_iindex_dict[mcapq]] - df_temp[\"BENCH_WEIGHT\"][mcapq_iindex_dict[mcapq]])))\n",
    "\n",
    "    return 0.1 - np.array(mcapq_list)\n",
    "\n",
    "def constraint8(x):\n",
    "\n",
    "    return 0.1 - abs(sum((x - BENCH) * df_temp[\"BETA\"]))\n",
    "\n",
    "def constraint10_1(x):\n",
    "    return np.minimum(x, BENCH).sum()\n",
    "\n",
    "def constraint10_2(x):\n",
    "    return 0.4 - np.minimum(x, BENCH).sum()\n",
    "\n",
    "def constraint11_1(x):\n",
    "    return (0.1 - math.sqrt(np.matrix(x - BENCH) * np.matrix(cov_df_temp) * np.matrix(x - BENCH).T))\n",
    "\n",
    "def constraint11_2(x):\n",
    "    return math.sqrt((np.matrix(x - BENCH) * np.matrix(cov_df_temp) * np.matrix(x - BENCH).T)) - 0.05\n",
    "\n",
    "con4 = {'type': 'eq', 'fun': constraint4}\n",
    "con5 = {'type': 'ineq', 'fun': constraint5}\n",
    "con6 = {'type': 'ineq', 'fun': constraint6}\n",
    "con7 = {'type': 'ineq', 'fun': constraint7}\n",
    "con8 = {'type': 'ineq', 'fun': constraint8}\n",
    "con10_1 = {'type': 'ineq', 'fun': constraint10_1}\n",
    "con10_2 = {'type': 'ineq', 'fun': constraint10_2}\n",
    "con11_1 = {'type': 'ineq', 'fun': constraint11_1}\n",
    "con11_2 = {'type': 'ineq', 'fun': constraint11_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.62708330154419 Seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "Time_Series_Data_path = \"C:/Users/user/Desktop/INFORMS/Timeseries_data_SP500.txt\"\n",
    "opt_path = \"C:/Users/user/Desktop/INFORMS/ResultsTemplate_Excel.xlsx\"\n",
    "\n",
    "TSD_df = pd.read_csv(Time_Series_Data_path, parse_dates= True, index_col= 'DATE', sep='\\t')\n",
    "template_df = pd.read_excel(opt_path, parse_dates=True, index_col='DATE', converters={'SEDOL': str})\n",
    "\n",
    "#Use os.path.basename to extract the file name then extract only digit part to specify each dataframe\n",
    "\n",
    "cov_mat_dict = {}\n",
    "work_dict = {}\n",
    "\n",
    "for file_path in glob.glob(\"C:/Users/user/Desktop/INFORMS/Riskmodels/cov_mat_*.csv\"):\n",
    "    date = os.path.basename(file_path).split('_')[2].replace('.csv','')\n",
    "    \n",
    "    work_dict[date] = pd.merge(TSD_df.loc[date], template_df.loc[date], how = 'outer', on = 'SEDOL').fillna(0)\n",
    "    work_dict[date].set_index('SEDOL', inplace = True)\n",
    "    \n",
    "    correct_index = work_dict[date].index.values\n",
    "    cov_mat_dict[date] = cov_df_generator(pd.read_csv(file_path), correct_index)\n",
    "\n",
    "#missing value\n",
    "cov_mat_dict['2016-07-06'].loc[\"BYT3MK1\", \"BYT3MK1\"] = 0.5\n",
    "\n",
    "cov_mat_dict['2016-07-06'].fillna(0, inplace = True)\n",
    "\n",
    "end = time.time()\n",
    "print(str(end - start) + ' Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any missing and 0 in any diagonal\n",
    "for date in cov_mat_dict:\n",
    "    if (cov_mat_dict[date].values.diagonal() == 0).any() or (cov_mat_dict[date].isnull().sum().sum() != 0):\n",
    "        print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>BETA</th>\n",
       "      <th>ALPHA_SCORE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>BENCH_WEIGHT</th>\n",
       "      <th>MCAP_Q</th>\n",
       "      <th>WEIGHTS</th>\n",
       "      <th>FOUR_WEEKLY_RETURN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEDOL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2038430</th>\n",
       "      <td>Financials</td>\n",
       "      <td>0.504252</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>Equity Office Properties Trust</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215460</th>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>0.548676</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>ConAgra Foods, Inc.</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.041111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963899</th>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>1.002699</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>Whole Foods Market, Inc.</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.075858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767228</th>\n",
       "      <td>Industrials</td>\n",
       "      <td>0.965206</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>Rockwell Collins, Inc.</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464165</th>\n",
       "      <td>Materials</td>\n",
       "      <td>0.763931</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>International Flavors &amp; Fragrances Inc.</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SECTOR      BETA  ALPHA_SCORE  \\\n",
       "SEDOL                                              \n",
       "2038430        Financials  0.504252    -0.000006   \n",
       "2215460  Consumer Staples  0.548676     0.000010   \n",
       "2963899  Consumer Staples  1.002699    -0.000017   \n",
       "2767228       Industrials  0.965206     0.000006   \n",
       "2464165         Materials  0.763931     0.000009   \n",
       "\n",
       "                                            NAME  BENCH_WEIGHT  MCAP_Q  \\\n",
       "SEDOL                                                                    \n",
       "2038430           Equity Office Properties Trust      0.001496       2   \n",
       "2215460                      ConAgra Foods, Inc.      0.001004       2   \n",
       "2963899                 Whole Foods Market, Inc.      0.000473       4   \n",
       "2767228                   Rockwell Collins, Inc.      0.000874       2   \n",
       "2464165  International Flavors & Fragrances Inc.      0.000290       5   \n",
       "\n",
       "         WEIGHTS  FOUR_WEEKLY_RETURN  \n",
       "SEDOL                                 \n",
       "2038430      0.0            0.153207  \n",
       "2215460      0.0           -0.041111  \n",
       "2963899      0.0           -0.075858  \n",
       "2767228      0.0            0.077737  \n",
       "2464165      0.0           -0.013832  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dict['2007-01-31'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ROW_INDEX</th>\n",
       "      <th>2038430</th>\n",
       "      <th>2215460</th>\n",
       "      <th>2963899</th>\n",
       "      <th>2767228</th>\n",
       "      <th>2464165</th>\n",
       "      <th>2947956</th>\n",
       "      <th>B8KQN82</th>\n",
       "      <th>2769503</th>\n",
       "      <th>2632650</th>\n",
       "      <th>2548616</th>\n",
       "      <th>...</th>\n",
       "      <th>2881537</th>\n",
       "      <th>2336747</th>\n",
       "      <th>2754060</th>\n",
       "      <th>2572303</th>\n",
       "      <th>2182779</th>\n",
       "      <th>2702791</th>\n",
       "      <th>2511328</th>\n",
       "      <th>2803014</th>\n",
       "      <th>2411138</th>\n",
       "      <th>2665861</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLUMN_INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2038430</th>\n",
       "      <td>0.077921</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>0.011941</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012491</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013662</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>0.013563</td>\n",
       "      <td>0.011272</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.019549</td>\n",
       "      <td>0.015134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215460</th>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>-0.000298</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.008092</td>\n",
       "      <td>0.008283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.006590</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>0.007633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963899</th>\n",
       "      <td>0.009329</td>\n",
       "      <td>-0.000298</td>\n",
       "      <td>0.170561</td>\n",
       "      <td>0.014857</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019160</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>0.019849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039549</td>\n",
       "      <td>0.010187</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>0.010569</td>\n",
       "      <td>0.029499</td>\n",
       "      <td>0.020015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767228</th>\n",
       "      <td>0.008081</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>0.014857</td>\n",
       "      <td>0.071527</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>0.024658</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028976</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.024680</td>\n",
       "      <td>0.008782</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>0.013067</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>0.025425</td>\n",
       "      <td>0.022367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464165</th>\n",
       "      <td>0.011941</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.058326</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012174</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.010290</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015725</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>0.013058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ROW_INDEX      2038430   2215460   2963899   2767228   2464165   2947956  \\\n",
       "COLUMN_INDEX                                                               \n",
       "2038430       0.077921  0.009070  0.009329  0.008081  0.011941  0.003488   \n",
       "2215460       0.009070  0.067025 -0.000298  0.006914  0.007516  0.006680   \n",
       "2963899       0.009329 -0.000298  0.170561  0.014857 -0.000337  0.008904   \n",
       "2767228       0.008081  0.006914  0.014857  0.071527  0.011042  0.011978   \n",
       "2464165       0.011941  0.007516 -0.000337  0.011042  0.058326  0.007445   \n",
       "\n",
       "ROW_INDEX     B8KQN82   2769503   2632650   2548616    ...      2881537  \\\n",
       "COLUMN_INDEX                                           ...                \n",
       "2038430           0.0  0.012491  0.012665  0.012539    ...     0.013662   \n",
       "2215460           0.0  0.007670  0.008092  0.008283    ...     0.004217   \n",
       "2963899           0.0  0.019160  0.021281  0.019849    ...     0.039549   \n",
       "2767228           0.0  0.016119  0.024658  0.020370    ...     0.028976   \n",
       "2464165           0.0  0.009201  0.013731  0.012408    ...     0.012174   \n",
       "\n",
       "ROW_INDEX      2336747   2754060   2572303   2182779   2702791   2511328  \\\n",
       "COLUMN_INDEX                                                               \n",
       "2038430       0.011992  0.013563  0.011272  0.005086  0.009537  0.011000   \n",
       "2215460       0.005525  0.008284  0.006590  0.006392  0.006160  0.007255   \n",
       "2963899       0.010187  0.023943  0.003363  0.000619  0.010350  0.009881   \n",
       "2767228       0.008151  0.024680  0.008782  0.013888  0.010228  0.013067   \n",
       "2464165       0.006949  0.012786  0.010936  0.010290  0.007281  0.015725   \n",
       "\n",
       "ROW_INDEX      2803014   2411138   2665861  \n",
       "COLUMN_INDEX                                \n",
       "2038430       0.010506  0.019549  0.015134  \n",
       "2215460       0.005533  0.011529  0.007633  \n",
       "2963899       0.010569  0.029499  0.020015  \n",
       "2767228       0.010608  0.025425  0.022367  \n",
       "2464165       0.007489  0.016248  0.013058  \n",
       "\n",
       "[5 rows x 493 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covariance Matrix\n",
    "cov_mat_dict['2007-01-31'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 131 dates\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} dates\".format(len(work_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-01-31\n",
      "493\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002498746295822637\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3465\n",
      "            Gradient evaluations: 7\n",
      "2007-02-28\n",
      "494\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002500746822217841\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3472\n",
      "            Gradient evaluations: 7\n",
      "2007-03-28\n",
      "494\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025019345464651773\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3472\n",
      "            Gradient evaluations: 7\n",
      "2007-04-25\n",
      "494\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025026609440609617\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3472\n",
      "            Gradient evaluations: 7\n",
      "2007-05-23\n",
      "494\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002500462356491462\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3472\n",
      "            Gradient evaluations: 7\n",
      "2007-06-20\n",
      "494\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025013235835236046\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3472\n",
      "            Gradient evaluations: 7\n",
      "2007-07-18\n",
      "493\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002500183621572712\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3465\n",
      "            Gradient evaluations: 7\n",
      "2007-08-15\n",
      "493\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501214667635753\n",
      "            Iterations: 8\n",
      "            Function evaluations: 3960\n",
      "            Gradient evaluations: 8\n",
      "2007-09-12\n",
      "493\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002500321749653598\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3465\n",
      "            Gradient evaluations: 7\n",
      "2007-10-10\n",
      "495\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024992753516509445\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3479\n",
      "            Gradient evaluations: 7\n",
      "2007-11-07\n",
      "495\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002496665829878763\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3479\n",
      "            Gradient evaluations: 7\n",
      "2007-12-05\n",
      "495\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501162641254288\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3479\n",
      "            Gradient evaluations: 7\n",
      "2008-01-02\n",
      "495\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002497827823318816\n",
      "            Iterations: 8\n",
      "            Function evaluations: 3976\n",
      "            Gradient evaluations: 8\n",
      "2008-01-30\n",
      "495\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501014793642754\n",
      "            Iterations: 8\n",
      "            Function evaluations: 3976\n",
      "            Gradient evaluations: 8\n",
      "2008-02-27\n",
      "495\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025040534628545134\n",
      "            Iterations: 8\n",
      "            Function evaluations: 3976\n",
      "            Gradient evaluations: 8\n",
      "2008-03-26\n",
      "495\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025029551958303895\n",
      "            Iterations: 8\n",
      "            Function evaluations: 3976\n",
      "            Gradient evaluations: 8\n",
      "2008-04-23\n",
      "495\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024992532620392413\n",
      "            Iterations: 8\n",
      "            Function evaluations: 3976\n",
      "            Gradient evaluations: 8\n",
      "2008-05-21\n",
      "495\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501913271184668\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3479\n",
      "            Gradient evaluations: 7\n",
      "2008-06-18\n",
      "495\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024999243587376916\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3479\n",
      "            Gradient evaluations: 7\n",
      "2008-07-16\n",
      "496\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002502343362666883\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3486\n",
      "            Gradient evaluations: 7\n",
      "2008-08-13\n",
      "497\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025013849919565162\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3493\n",
      "            Gradient evaluations: 7\n",
      "2008-09-10\n",
      "497\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501945066678491\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3493\n",
      "            Gradient evaluations: 7\n",
      "2008-10-08\n",
      "497\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002497620783231965\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3493\n",
      "            Gradient evaluations: 7\n",
      "2008-11-05\n",
      "497\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024997969539872623\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3493\n",
      "            Gradient evaluations: 7\n",
      "2008-12-03\n",
      "497\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.024636234885312358\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.024636234885312358\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.024636234885312358\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.024636234885312358\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025006468697430055\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3493\n",
      "            Gradient evaluations: 7\n",
      "2008-12-31\n",
      "497\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.02578513593550812\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025008818854788044\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3493\n",
      "            Gradient evaluations: 7\n",
      "2009-01-28\n",
      "497\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.02666191783764991\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.02666191783764991\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.02666191783764991\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.02666191783764991\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.02666191783764991\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.02666191783764991\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00249883874493625\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3493\n",
      "            Gradient evaluations: 7\n",
      "2009-02-25\n",
      "497\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.026671799961822742\n",
      "            Iterations: 1\n",
      "            Function evaluations: 499\n",
      "            Gradient evaluations: 1\n",
      "2009-03-25\n",
      "497\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501976808024569\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3493\n",
      "            Gradient evaluations: 7\n",
      "2009-04-22\n",
      "497\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025004181970914195\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3493\n",
      "            Gradient evaluations: 7\n",
      "2009-05-20\n",
      "497\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002502390108204586\n",
      "            Iterations: 8\n",
      "            Function evaluations: 3992\n",
      "            Gradient evaluations: 8\n",
      "2009-06-17\n",
      "497\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002502818168236767\n",
      "            Iterations: 10\n",
      "            Function evaluations: 4990\n",
      "            Gradient evaluations: 10\n",
      "2009-07-15\n",
      "497\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025001772803824674\n",
      "            Iterations: 8\n",
      "            Function evaluations: 3992\n",
      "            Gradient evaluations: 8\n",
      "2009-08-12\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025014797470807783\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2009-09-09\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002499108886140936\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2009-10-07\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501748928789251\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2009-11-04\n",
      "497\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024985950500358203\n",
      "            Iterations: 8\n",
      "            Function evaluations: 3992\n",
      "            Gradient evaluations: 8\n",
      "2009-12-02\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002499035914213063\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2009-12-30\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024982273228182812\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2010-01-27\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025035790366793784\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2010-02-24\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025005981917501155\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3501\n",
      "            Gradient evaluations: 7\n",
      "2010-03-24\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002503685348009753\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2010-04-21\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025001226486365004\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2010-05-19\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00250168322492898\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2010-06-16\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025039485753225415\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2010-07-14\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002497510534322301\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2010-08-11\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025043107565266144\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2010-09-08\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024993208035192856\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2010-10-06\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002502439013781022\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2010-11-03\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025023106938015325\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2010-12-01\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501250456059918\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4001\n",
      "            Gradient evaluations: 8\n",
      "2010-12-29\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025009529398881407\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2011-01-26\n",
      "498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002505506891729193\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2011-02-23\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501288750311828\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2011-03-23\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002499943553992042\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2011-04-20\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00250157032023338\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4001\n",
      "            Gradient evaluations: 8\n",
      "2011-05-18\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025022751001415417\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2011-06-15\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501888865550439\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2011-07-13\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025027219688062152\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2011-08-10\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501186856982051\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2011-09-07\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025007325789943445\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2011-10-05\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024979978438538566\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2011-11-02\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501929142927448\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2011-11-30\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024999936234450806\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2011-12-28\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501255215952264\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-01-25\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002500567249417199\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-02-22\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002503368972598731\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-03-21\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025001322950715162\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-04-18\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002500722453390283\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-05-16\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025021329054805705\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2012-06-13\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002502021870659273\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-07-11\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025006575469532317\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-08-08\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024992521100487618\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-09-05\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002495933792815381\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-10-03\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024987288542506936\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-10-31\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024984548629455364\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2012-11-28\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501723758175904\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2012-12-26\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025011565165611463\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4000\n",
      "            Gradient evaluations: 8\n",
      "2013-01-23\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002499907289675339\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2013-02-20\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024991487627691817\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2013-03-20\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024999698885143145\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2013-04-17\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002502307801756809\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3501\n",
      "            Gradient evaluations: 7\n",
      "2013-05-15\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002496603556298501\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2013-06-12\n",
      "498\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024990385629655664\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3500\n",
      "            Gradient evaluations: 7\n",
      "2013-07-10\n",
      "499\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024994565437443583\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3507\n",
      "            Gradient evaluations: 7\n",
      "2013-08-07\n",
      "499\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501129112290881\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3507\n",
      "            Gradient evaluations: 7\n",
      "2013-09-04\n",
      "499\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025006312980645332\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3507\n",
      "            Gradient evaluations: 7\n",
      "2013-10-02\n",
      "499\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025023598406925494\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3507\n",
      "            Gradient evaluations: 7\n",
      "2013-10-30\n",
      "499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024995915631885212\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3507\n",
      "            Gradient evaluations: 7\n",
      "2013-11-27\n",
      "499\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024984318561635664\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3508\n",
      "            Gradient evaluations: 7\n",
      "2013-12-25\n",
      "499\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024973038763407163\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4008\n",
      "            Gradient evaluations: 8\n",
      "2014-01-22\n",
      "499\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025018958682051467\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3507\n",
      "            Gradient evaluations: 7\n",
      "2014-02-19\n",
      "499\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002503420260228792\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3507\n",
      "            Gradient evaluations: 7\n",
      "2014-03-19\n",
      "499\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00250131037845567\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3507\n",
      "            Gradient evaluations: 7\n",
      "2014-04-16\n",
      "500\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00250154816222717\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3514\n",
      "            Gradient evaluations: 7\n",
      "2014-05-14\n",
      "500\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024989386283297355\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4016\n",
      "            Gradient evaluations: 8\n",
      "2014-06-11\n",
      "500\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002499869302576677\n",
      "            Iterations: 6\n",
      "            Function evaluations: 3013\n",
      "            Gradient evaluations: 6\n",
      "2014-07-09\n",
      "500\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002499712570625762\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3514\n",
      "            Gradient evaluations: 7\n",
      "2014-08-06\n",
      "500\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002502456534716232\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3514\n",
      "            Gradient evaluations: 7\n",
      "2014-09-03\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024993712264067664\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4024\n",
      "            Gradient evaluations: 8\n",
      "2014-10-01\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024988972157949734\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4024\n",
      "            Gradient evaluations: 8\n",
      "2014-10-29\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024985537603272705\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3521\n",
      "            Gradient evaluations: 7\n",
      "2014-11-26\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024984147394213068\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3521\n",
      "            Gradient evaluations: 7\n",
      "2014-12-24\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025028763930253994\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3521\n",
      "            Gradient evaluations: 7\n",
      "2015-01-21\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501703650495419\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3521\n",
      "            Gradient evaluations: 7\n",
      "2015-02-18\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002504029071592218\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4024\n",
      "            Gradient evaluations: 8\n",
      "2015-03-18\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002501336913527243\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3521\n",
      "            Gradient evaluations: 7\n",
      "2015-04-15\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002502001730943363\n",
      "            Iterations: 6\n",
      "            Function evaluations: 3018\n",
      "            Gradient evaluations: 6\n",
      "2015-05-13\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025058152870285674\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3521\n",
      "            Gradient evaluations: 7\n",
      "2015-06-10\n",
      "501\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025043308642836606\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3521\n",
      "            Gradient evaluations: 7\n",
      "2015-07-08\n",
      "502\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024972910820532782\n",
      "            Iterations: 6\n",
      "            Function evaluations: 3025\n",
      "            Gradient evaluations: 6\n",
      "2015-08-05\n",
      "502\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002504181703996292\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3528\n",
      "            Gradient evaluations: 7\n",
      "2015-09-02\n",
      "502\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025041349767189443\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3528\n",
      "            Gradient evaluations: 7\n",
      "2015-09-30\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025023897396667986\n",
      "            Iterations: 6\n",
      "            Function evaluations: 3042\n",
      "            Gradient evaluations: 6\n",
      "2015-10-28\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025032626114270652\n",
      "            Iterations: 6\n",
      "            Function evaluations: 3043\n",
      "            Gradient evaluations: 6\n",
      "2015-11-25\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025027437488175253\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3549\n",
      "            Gradient evaluations: 7\n",
      "2015-12-23\n",
      "504\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025034712836980093\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3542\n",
      "            Gradient evaluations: 7\n",
      "2016-01-20\n",
      "504\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025006525522948664\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3542\n",
      "            Gradient evaluations: 7\n",
      "2016-02-17\n",
      "504\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025000574868732453\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3542\n",
      "            Gradient evaluations: 7\n",
      "2016-03-16\n",
      "504\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002504447854247819\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3542\n",
      "            Gradient evaluations: 7\n",
      "2016-04-13\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025023231439732967\n",
      "            Iterations: 8\n",
      "            Function evaluations: 4056\n",
      "            Gradient evaluations: 8\n",
      "2016-05-11\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025013342255133697\n",
      "            Iterations: 6\n",
      "            Function evaluations: 3043\n",
      "            Gradient evaluations: 6\n",
      "2016-06-08\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025046593670409165\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3549\n",
      "            Gradient evaluations: 7\n",
      "2016-07-06\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025032068266891043\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3549\n",
      "            Gradient evaluations: 7\n",
      "2016-08-03\n",
      "505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002504451557932541\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3549\n",
      "            Gradient evaluations: 7\n",
      "2016-08-31\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025041102160642667\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3549\n",
      "            Gradient evaluations: 7\n",
      "2016-09-28\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025016764141361086\n",
      "            Iterations: 6\n",
      "            Function evaluations: 3043\n",
      "            Gradient evaluations: 6\n",
      "2016-10-26\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025023114444012347\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3549\n",
      "            Gradient evaluations: 7\n",
      "2016-11-23\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002502003211318214\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3549\n",
      "            Gradient evaluations: 7\n",
      "2016-12-21\n",
      "505\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002500801734154209\n",
      "            Iterations: 7\n",
      "            Function evaluations: 3549\n",
      "            Gradient evaluations: 7\n",
      "6701.220558166504 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# The dictionary for the optimal solutions of each date\n",
    "optimal_solutions = {}\n",
    "\n",
    "for date in work_dict:\n",
    "    if (date == '2007-01-03'):\n",
    "        continue\n",
    "        \n",
    "    print(date)\n",
    "    \n",
    "    df_temp = work_dict[date].copy()\n",
    "    cov_df_temp = cov_mat_dict[date].copy()\n",
    "    \n",
    "    # For functions\n",
    "    LAMBDA = 1\n",
    "    BENCH = df_temp[\"BENCH_WEIGHT\"]\n",
    "    ALPHA = df_temp['ALPHA_SCORE']\n",
    "    \n",
    "    mcapq_iindex_dict = {}\n",
    "    sector_iindex_dict = {}\n",
    "\n",
    "    num_of_selection = 70\n",
    "\n",
    "    while df_temp.groupby([\"MCAP_Q\", \"SECTOR\"]).size().multiply(num_of_selection / len(df_temp)).round().sum() > 70:\n",
    "        num_of_selection -= 1\n",
    "\n",
    "    type_num = df_temp.groupby([\"MCAP_Q\", \"SECTOR\"]).size().multiply(num_of_selection / len(df_temp)).round().to_dict()\n",
    "\n",
    "\n",
    "    # Integer index of all sector type stocks\n",
    "    for sector in df_temp[\"SECTOR\"].unique():\n",
    "        sector_iindex_dict[sector] = [df_temp.index.get_loc(i) for i in df_temp[df_temp[\"SECTOR\"] == sector].index]\n",
    "\n",
    "    # Integer index of all mcapq type stocks\n",
    "    for mcapq in range(1, 6):\n",
    "        mcapq_iindex_dict[mcapq] = [df_temp.index.get_loc(i) for i in df_temp[df_temp[\"MCAP_Q\"] == mcapq].index]\n",
    "    \n",
    "    print(len(df_temp))\n",
    "    \n",
    "    signal = 0\n",
    "    counter = 0\n",
    "    \n",
    "    while signal == 0:\n",
    "        \n",
    "        selected_index = set()\n",
    "        \n",
    "        for key, value in type_num.items():\n",
    "            selected_index.update(set(np.random.choice(df_temp[(df_temp[\"MCAP_Q\"] == key[0]) & (df_temp[\"SECTOR\"] == key[1])].\\\n",
    "                                                       index.values, size = int(value), replace = False)))\n",
    "\n",
    "        \n",
    "        bnds = []\n",
    "\n",
    "        for i in df_temp.index.values:\n",
    "            if i in selected_index:\n",
    "                bnds.append((0.001, 1))\n",
    "            else:\n",
    "                bnds.append((0, 0))\n",
    "\n",
    "\n",
    "        cons = [con4, con5, con6, con7, con8, con10_1, con10_2, con11_1, con11_2]\n",
    "\n",
    "\n",
    "        sol = minimize(objective, df_temp[\"WEIGHTS\"], method='SLSQP', bounds=bnds, constraints=cons, options= {'disp': True})\n",
    "        \n",
    "        if sol.success:\n",
    "            optimal_solutions[date] = sol.x\n",
    "            signal = 1\n",
    "        elif counter > 10:\n",
    "            break\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(str(end - start) + \" seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
